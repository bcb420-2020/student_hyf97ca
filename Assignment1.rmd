---
title: Assignment 1 Notebook
author: Yi Fei Huang
date: 2020-02-04
output: html_notebook
---
## 0- Load libraries
```{R, error=FALSE, message=FALSE, warning=FALSE}
library("GEOquery")
library("biomaRt")
library("edgeR")
```


## 1â€“ Download the data

I chose to use the GEO web app to look for an appropriate dataset.

As recorded in my journal:

"I selected Homo sapiens as organism, put publication date from 2017 January through 2020 December, specified sample counts from 6 to 12, and the presence of a supplementary file in TXT format.
In the actual search query, I used '(gse[filter]) neural'."

From the results, on page 2 as of 2020-02-02 I selected GSE127268, which was a heterozygous dataset, then thought better and selected GSE120200, a sister homozygous dataset because homozygous data should result in more pronounced differential expression.

Some basic info about the dataset from GEO, using code adapted from Slide 17 in Lecture 4:
```{R, message=FALSE}
gse <- getGEO("GSE120200",GSEMatrix=FALSE)
current_gpl <- names(GPLList(gse))[1]
current_gpl_info <- Meta(getGEO(current_gpl))
```

**Platform title:** `r current_gpl_info$title`

**Submission date** `r current_gpl_info$submission_date`

**Last update date:** `r current_gpl_info$last_update_date`

**Organisms:**  `r current_gpl_info$organism`

To summarize the paper, they collected wild type cultured human neurons and edited cell lines that knocked out the ASXL1 gene. The knockout was shown to interfere with neural crest formation. Part of the experiment was global RNA sequencing to find what changes in expression occur after ASXL1 is knocked out.

Note that inside the paper, chicken embryos were used at various stages of experimentation. This dataset, however, is only about cultured human neurons.

Using the code from slide 56 of Lecture 3:
```{R}
sfiles <- getGEOSuppFiles('GSE120200')
counts <- read.delim(rownames(sfiles)[1],header=TRUE, check.names = FALSE)
counts_matrix <- counts[,-1]
rownames(counts_matrix) <- counts[,1]
head(counts)
head(counts_matrix)
```
### 2- overview statistics

```{R}
#are there any duplicates? Code adapted from Lecture 4 slide 23
summarized_gene_counts <- sort(table(counts$Geneid),decreasing = TRUE)
summarized_gene_counts[which(summarized_gene_counts>1)[1:10]]

```
This means all the ensembl IDs are identical.

How many genes are there?
```{R}
dim(counts)

```
Are they all genes?
```{R}
tail(counts)

```
No, ERCC isn't an Ensembl gene ID.

So what is ERCC?
[It seems like a quality control.](https://www.nist.gov/programs-projects/external-rna-controls-consortium)

```{R}
#Did we get any reads in the controls?
sum(rowSums(counts[grep("ERCC", counts$Geneid),-1]))

```
It looks like they will be filtered out for having a low count of 0, so we can ignore them safely.
This also tells us that there wasn't any external contamination found using the ERCC kit.

Filtering out low counts using code adapted from Lecture 4 Slide 25:
```{R}
cpms <- cpm(counts[,-1])
rownames(cpms) <- counts[,1]

#We have 3 'normal' samples and 7 'diseased' samples so let's use 3, since that is the smallest group of replicates.
keep <- rowSums(cpms > 1) >= 3
counts_filtered <- counts[keep,]
#delete autogenerated rownames left over from counts
rownames(counts_filtered) = c()
dim(counts_filtered)
```
We removed two thirds of the gene ids with this filtering step.

Now to make graphs. Adapting the code from Slide 36 in Lecture 4:
```{R}
#Boxplot:
boxplot_data <- log2(cpm(counts_filtered[,-1]))
rownames(boxplot_data) = counts_filtered[,1]
boxplot(boxplot_data, xlab = "Samples", ylab = "log2 CPM", 
        las = 2, cex = 0.5, cex.lab = 0.5,
        cex.axis = 0.5, main = "ASXL1 RNASeq Samples")
abline(h = median(apply(boxplot_data, 2, median)), col = "orangered", lwd = 0.6, lty = "dashed")
```
Strange that we are getting outliers of -inf. That means there has to be 0 values. but didn't we filter them out?

```{R}
min(boxplot_data)
min(counts_filtered[,-1])
```
There are probably 0s in the columns.

Density plot: (Using code adapted from Lecture 4 slide 38)
```{R}
counts_density <- apply(log2(cpm(counts_filtered[,-1])), 2, density)

xlim <- 0; ylim <- 0
    for (i in 1:length(counts_density)) {
      xlim <- range(c(xlim, counts_density[[i]]$x)); 
      ylim <- range(c(ylim, counts_density[[i]]$y))
    }
cols <- rainbow(length(counts_density))
    
    ltys <- rep(1, length(counts_density))
plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
         ylab="Smoothing density of log2-CPM", main="", cex.lab = 0.85)
    #plot each line
    for (i in 1:length(counts_density)) lines(counts_density[[i]], col=cols[i], lty=ltys[i])
    #create legend
    legend("topright", colnames(boxplot_data),  
           col=cols, lty=ltys, cex=0.75, 
           border ="red",  text.col = "green4", 
           merge = TRUE, bg = "gray80")
```
The different samples look pretty close to each other, with the exception of WT2, but even that is still a reasonable deviation in shape.

### 3- convert to HUGO
```{R}
conversion_stash <- "data_id_conversion.rds"
if(file.exists(conversion_stash)){
  data_id_conversion <- readRDS(conversion_stash)
} else {
  ensembl <- useMart("ensembl")
  data_id_conversion <- getBM(attributes = c("ensembl_gene_id","hgnc_symbol"),
                            filters = c("ensembl_gene_id"),
                            values = counts$Geneid, #use IDs from before the filtering stage
                            mart = ensembl)
  saveRDS(data_id_conversion, conversion_stash)
}
head(data_id_conversion)
```

If the ensembl servers are flaky I have included a file called "data_id_conversion_backup.rds" which can be renamed to "data_id_conversion.rds" to be able to proceed.

```{R}
#Duplicate hgnc symbols?
summarized_hgnc_counts <- sort(table(data_id_conversion$hgnc_symbol),decreasing = TRUE)
summarized_hgnc_counts[which(summarized_hgnc_counts>1)[1:10]]
dim(summarized_hgnc_counts[which(summarized_hgnc_counts>1)])

#Duplicate ensemble ids?
summarized_ensemble_counts <- sort(table(data_id_conversion$ensembl_gene_id),decreasing = TRUE)
summarized_ensemble_counts[which(summarized_ensemble_counts>1)[1:2]]
dim(summarized_ensemble_counts[which(summarized_ensemble_counts>1)])

```
There are `r dim(summarized_hgnc_counts[which(summarized_hgnc_counts>1)])` duplicated hgnc symbols when mapped from ensembl gene ids.

I looked on the [ensembl website](https://useast.ensembl.org/Homo_sapiens/Gene/Summary?g=ENSG00000225845;r=CHR_HSCHR6_MHC_MCF_CTG1:32470120-32483292) as well as the [HGNC website](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/HGNC:1142) and found that at least for BTNL2, there were multiple splices for it that corresponded to all the different ensembl gene ids. 

In such a case, according to MacDonald (2016) on [Bioconductor Forums](https://support.bioconductor.org/p/90185/) if the transcript lengths were significantly different, summing up all the reads wouldn't necessarily be the correct decision. There is a good chance, however, that the genes in question do not necessarily have reads, and in the step where we remove all the entries that have low counts they might not exist anymore. Note that we made the gene id mapping using the ids before the filtering step.

Essentially like in slide 24 of Lecture 4, we are ignoring the problem and hope that we don't actually have to deal with it.

There are also `r dim(summarized_hgnc_counts[which(summarized_ensemble_counts>1)])` duplicated ensembl ids in the mapping.
Since this isn't a high number, we can look at them manually and see what happened:
```{R}
dups <- which(summarized_ensemble_counts>1)
data_id_conversion[names(dups)[1] == data_id_conversion$ensembl_gene_id | names(dups)[2] == data_id_conversion$ensembl_gene_id,]
```
Googling C12orf74, it seems to be an older symbol. I presume the later entry for both of these duplicated IDs is the newer symbol.

### 4 - Normalization

Apply TMM by using edgeR. I picked TMM arbitrarily because it was what we used in lecture, it is specialized for RNA-seq, and in addition, it is what I usually hear about in discussions of normalization.

```{R}
counts_filtered_matrix <- as.matrix(counts_filtered[,-1])
rownames(counts_filtered_matrix) <- counts_filtered$Geneid
samples <- c(rep("WT", 3), rep ("HOM", 7))
d = DGEList(counts=counts_filtered_matrix, group=samples)
d = calcNormFactors(d)
normalized_filtered_counts <- cpm(d)

normalized_counts_density <- apply(log2(normalized_filtered_counts), 2, density)

xlim <- 0; ylim <- 0
    for (i in 1:length(normalized_counts_density)) {
      xlim <- range(c(xlim, normalized_counts_density[[i]]$x)); 
      ylim <- range(c(ylim, normalized_counts_density[[i]]$y))
    }
cols <- rainbow(length(normalized_counts_density))
    
    ltys <- rep(1, length(normalized_counts_density))

par(mfrow=c(2,2))

plot(normalized_counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
         ylab="Smoothing density of log2-CPM", main="Normalized", cex.lab = 0.85)
    #plot each line
    for (i in 1:length(normalized_counts_density)) lines(normalized_counts_density[[i]], col=cols[i], lty=ltys[i])
    #create legend
    legend("topright", colnames(boxplot_data),  
           col=cols, lty=ltys, cex=0.75, 
           border ="red",  text.col = "green4", 
           merge = TRUE, bg = "gray80")

#compare to old plot
plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
         ylab="Smoothing density of log2-CPM", main="Not Normalized", cex.lab = 0.85)
    #plot each line
    for (i in 1:length(counts_density)) lines(counts_density[[i]], col=cols[i], lty=ltys[i])
    #create legend
    legend("topright", colnames(boxplot_data),  
           col=cols, lty=ltys, cex=0.75, 
           border ="red",  text.col = "green4", 
           merge = TRUE, bg = "gray80")
    
    
#boxplots
    #Boxplot:
boxplot_data_normalized <- log2(normalized_filtered_counts)
boxplot(boxplot_data_normalized, xlab = "Samples", ylab = "log2 CPM", 
        las = 2, cex = 0.5, cex.lab = 0.5,
        cex.axis = 0.5, main = "Normalized")
abline(h = median(apply(boxplot_data_normalized, 2, median)), col = "orangered", lwd = 0.6, lty = "dashed")

#old boxplot
boxplot(boxplot_data, xlab = "Samples", ylab = "log2 CPM", 
        las = 2, cex = 0.5, cex.lab = 0.5,
        cex.axis = 0.5, main = "Not Normalized")
abline(h = median(apply(boxplot_data, 2, median)), col = "orangered", lwd = 0.6, lty = "dashed")
```
Looking at these plots, I don't see much, if any difference. Nothing striking like what was presented in lecture.

```{R}

plotMDS(d, labels=rownames(samples),
  col = c("darkgreen","blue")[factor(samples)])

model_design <- model.matrix(~samples)

d <- estimateDisp(d, model_design)

par(mfrow=c(1,2))

plotBCV(d,col.tagwise = "black",col.common = "red")

plotMeanVar(d, show.raw.vars = TRUE,
            show.tagwise.vars=TRUE, NBline=TRUE, 
            show.ave.raw.vars = TRUE,show.binned.common.disp.vars = TRUE)
```

The MDS plot looks good, WT and HOM are well separated into different quadrants.
The BCV plot and mean-variance plot look similar to the ones in the slides.

### 5 - Apply identifier mapping

```{R}
normalized_filtered_counts_annot <- merge(data_id_conversion, normalized_filtered_counts, by.x=1, by.y=0, all.y=TRUE)
#final_data_frame <- as.data.frame(normalized_filtered_counts)

ensembl_id_missing_gene <- normalized_filtered_counts_annot$ensembl_gene_id[
  which(is.na(normalized_filtered_counts_annot$hgnc_symbol) | normalized_filtered_counts_annot$hgnc_symbol == '')]
#How many ensembl ids don't have symbols?
length(ensembl_id_missing_gene)

hgnc_table <- normalized_filtered_counts_annot[which(!(normalized_filtered_counts_annot$ensembl_gene_id %in% ensembl_id_missing_gene)),]

#any NAs left?
which(is.na(hgnc_table$hgnc_symbol))

#any duplicates in ensembl gene ids?
duplicated(hgnc_table$ensemble_gene_id)

#any duplicates in hgnc ids?
length(which(duplicated(hgnc_table$hgnc_symbol)))

#if there were duplicates, this is how I would've summed them up, against the advice of MacDonald:
#unique_hgnc <- aggregate(hgnc_table[,3:12], list(hgnc_table[,2]), FUN="sum")

```

The idea to use the aggregate function came from "Jimbou" (2015) answering a question on [Biostars](https://www.biostars.org/p/167028/).

There are `r length(which(duplicated(hgnc_table$hgnc_symbol)))` duplicates of HGNC symbols that we need to resolve.
Lucky us!

Now that all our worries have been miraculously solved by the filtering step except for `r length(ensembl_id_missing_gene) * 100 / nrow(normalized_filtered_counts)`% of the dataset being removed due to lack of HGNC symbols, we can create the final data frame.

```{R}
final_a1_data = as.data.frame(hgnc_table[3:12])
rownames(final_a1_data) <- hgnc_table[,2]
sample(final_a1_data, 10)
```
### Final questions

I already answered most of these questions above, but I will formalize them here.

* What are the control and test conditions of the dataset?

    Control condition: wild type ASXL1 gene. Test condition: edited ASXL1 gene to knock it out.

* Why is the dataset of interest to you?

    The dataset is of interest because the mechanism of neural cell migration is interesting to me. Understanding this mechanism has implications for brain development and therefore the basis of human intelligence.

* Were there expression values that were not unique for specific genes? How did you handle these?

    After the filtering step, there were no expression values that were not unique.

* Were there expression values that could not be mapped to current HUGO symbols?

    There were many expression values that could not be mapped to current HUGO symbols. Most of them appear to be in non-coding regions.

* How many outliers were removed?

    I didn't remove any outliers of extreme expression, but almost two-thirds of the dataset was removed because of low expression.

* How did you handle replicates?

    Since the experiment was relatively simple, I simply made WT and HOM groups for control and experimental samples.

* What is the final coverage of your dataset?

    Out of `r length(grep("ENSG", counts$Geneid))` genes we started with, we ended up with `r nrow(final_a1_data)` genes. That is `r nrow(final_a1_data) * 100 / length(grep("ENSG", counts$Geneid))`% coverage.
    
# References

